{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Timeseries demo\n",
    "<br>\n",
    "There's two ways to extract a time series: for a point or for a polygon. There's an example for both below. <br>\n",
    "If you prefer a GUI, then check out [https://viewer.terrascope.be/], and go to <b>Area of Interest</b>. <br>\n",
    "When you use this Notebook, you have access to more layers than in the GUI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "tsvBaseURL='https://services.terrascope.be/timeseries/v1.0/ts/'\n",
    "\n",
    "response = requests.get(tsvBaseURL) #this returns the layers that are available\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.status_code == 200:\n",
    "    layerlist = response.json()['layers']\n",
    "else:\n",
    "    raise IOError(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's investigate the layers that are offered. The list is not sorted, so let's sort it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layersSorted = sorted(layerlist, key=lambda k: k['name']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOPAR_FAPAR300_V1_GLOBAL                 129  2013-10-16T00:00:00 to 2017-05-04T00:00:00\n",
      "CGLS_LC100_COV_LCCS                      1614  2015-07-04T00:00:00 to 2020-08-24T00:00:00\n",
      "CHIRPS_RAINFALL                           792  1998-01-11T00:00:00 to 2020-07-21T00:00:00\n",
      "DCS4COP_CHL_V103                          799  2016-01-02T10:54:42 to 2020-05-30T12:27:01\n",
      "DCS4COP_CLOUDCOVER_V103                   810  2016-01-02T10:54:42 to 2020-05-30T12:27:01\n",
      "DCS4COP_FLANDERS_CHL                      454  2017-01-02T11:14:42 to 2018-10-31T11:02:01\n",
      "DCS4COP_FLANDERS_CHL_V100                 750  2017-01-02T11:14:42 to 2020-02-10T10:52:01\n",
      "DCS4COP_FLANDERS_CHL_V102                 890  2017-01-02T11:14:42 to 2020-06-02T10:56:31\n",
      "DCS4COP_FLANDERS_CLOUDCOVER               454  2017-01-02T11:14:42 to 2018-10-31T11:02:01\n",
      "DCS4COP_FLANDERS_CLOUDCOVER_L8            159  2017-01-03T10:40:38 to 2018-08-27T10:33:22\n",
      "DCS4COP_FLANDERS_CLOUDCOVER_L8_V100        38  2019-05-10T10:30:59 to 2019-05-31T10:53:42\n",
      "DCS4COP_FLANDERS_CLOUDCOVER_V100          927  2017-01-02T11:14:42 to 2020-02-10T11:43:49\n",
      "DCS4COP_FLANDERS_CLOUDCOVER_V102          894  2017-01-02T11:14:42 to 2020-06-02T10:56:31\n",
      "DCS4COP_FLANDERS_SPM                      454  2017-01-02T11:14:42 to 2018-10-31T11:02:01\n",
      "DCS4COP_FLANDERS_SPM_L8                   159  2017-01-03T10:40:38 to 2018-08-27T10:33:22\n",
      "DCS4COP_FLANDERS_SPM_V100                 748  2017-01-02T11:14:42 to 2020-02-10T10:52:01\n",
      "DCS4COP_FLANDERS_SPM_V102                 890  2017-01-02T11:14:42 to 2020-06-02T10:56:31\n",
      "DCS4COP_FLANDERS_TUR                      454  2017-01-02T11:14:42 to 2018-10-31T11:02:01\n",
      "DCS4COP_FLANDERS_TUR_L8                   159  2017-01-03T10:40:38 to 2018-08-27T10:33:22\n",
      "DCS4COP_FLANDERS_TUR_V100                 749  2017-01-02T11:14:42 to 2020-02-10T10:52:01\n",
      "DCS4COP_FLANDERS_TUR_V102                 891  2017-01-02T11:14:42 to 2020-06-02T10:56:31\n",
      "DCS4COP_NDAVI_V103                          4  2020-05-29T11:21:21 to 2020-05-30T12:27:01\n",
      "DCS4COP_SPM_V103                          727  2016-01-02T00:00:00 to 2020-06-16T00:00:00\n",
      "DCS4COP_TUR_V103                          727  2016-01-02T00:00:00 to 2020-06-16T00:00:00\n",
      "FSTEP_SENTINEL2_FAPAR                     150  2016-01-05T00:00:00 to 2019-02-08T00:00:00\n",
      "FSTEP_SENTINEL2_FAPAR_MASK                154  2016-01-05T00:00:00 to 2019-02-08T00:00:00\n",
      "FSTEP_SENTINEL2_FCOVER                    149  2016-01-05T00:00:00 to 2019-02-08T00:00:00\n",
      "FSTEP_SENTINEL2_FCOVER_MASK               154  2016-01-05T00:00:00 to 2019-02-08T00:00:00\n",
      "FSTEP_SENTINEL2_LAI                       149  2016-01-05T00:00:00 to 2019-02-08T00:00:00\n",
      "FSTEP_SENTINEL2_LAI_MASK                  154  2016-01-05T00:00:00 to 2019-02-08T00:00:00\n",
      "FSTEP_SENTINEL2_NDVI                      149  2016-01-05T00:00:00 to 2019-02-08T00:00:00\n",
      "FSTEP_SENTINEL2_NDVI_MASK                 154  2016-01-05T00:00:00 to 2019-02-08T00:00:00\n",
      "FSTEP_WEEKLY_METEO_AVG_TEMPERATURE        111  2016-01-01T00:00:00 to 2018-02-05T00:00:00\n",
      "FSTEP_WEEKLY_METEO_RAINFALL               109  2016-01-01T08:00:00 to 2018-01-22T08:00:00\n",
      "PROBAV_L3_S10_TOC_NDVI_333M               247  2013-10-11T00:00:00 to 2020-08-11T00:00:00\n",
      "S1_GRD_GAMMA0                            1785  2015-01-03T00:00:00 to 2020-08-26T00:00:00\n",
      "S1_GRD_GAMMA0_ASCENDING                   780  2015-01-03T00:00:00 to 2020-06-15T00:00:00\n",
      "S1_GRD_GAMMA0_ASCENDING_ANGLE             780  2015-01-03T00:00:00 to 2020-06-15T00:00:00\n",
      "S1_GRD_GAMMA0_ASCENDING_VH                780  2015-01-03T00:00:00 to 2020-06-15T00:00:00\n",
      "S1_GRD_GAMMA0_ASCENDING_VV                780  2015-01-03T00:00:00 to 2020-06-15T00:00:00\n",
      "S1_GRD_GAMMA0_DESCENDING                 1043  2015-01-07T00:00:00 to 2020-06-15T00:00:00\n",
      "S1_GRD_GAMMA0_DESCENDING_ANGLE           1043  2015-01-07T00:00:00 to 2020-06-15T00:00:00\n",
      "S1_GRD_GAMMA0_DESCENDING_VH              1043  2015-01-07T00:00:00 to 2020-06-15T00:00:00\n",
      "S1_GRD_GAMMA0_DESCENDING_VV              1043  2015-01-07T00:00:00 to 2020-06-15T00:00:00\n",
      "S1_GRD_GAMMA0_VH                         1785  2015-01-03T00:00:00 to 2020-08-26T00:00:00\n",
      "S1_GRD_GAMMA0_VV                         1785  2015-01-03T00:00:00 to 2020-08-26T00:00:00\n",
      "S1_GRD_SIGMA0_ASCENDING                  1786  2015-01-03T00:00:00 to 2020-08-26T00:00:00\n",
      "S1_GRD_SIGMA0_ASCENDING_ANGLE            1786  2015-01-03T00:00:00 to 2020-08-26T00:00:00\n",
      "S1_GRD_SIGMA0_ASCENDING_VH               1786  2015-01-03T00:00:00 to 2020-08-26T00:00:00\n",
      "S1_GRD_SIGMA0_ASCENDING_VV               1786  2015-01-03T00:00:00 to 2020-08-26T00:00:00\n",
      "S1_GRD_SIGMA0_DESCENDING                 1786  2015-01-03T00:00:00 to 2020-08-26T00:00:00\n",
      "S1_GRD_SIGMA0_DESCENDING_ANGLE           1786  2015-01-03T00:00:00 to 2020-08-26T00:00:00\n",
      "S1_GRD_SIGMA0_DESCENDING_VH              1786  2015-01-03T00:00:00 to 2020-08-26T00:00:00\n",
      "S1_GRD_SIGMA0_DESCENDING_VV              1786  2015-01-03T00:00:00 to 2020-08-26T00:00:00\n",
      "S2_CLOUDCOVER_GLOBAL                     1577  2015-07-04T00:00:00 to 2020-08-27T00:00:00\n",
      "S2_CLOUDCOVER_GLOBAL2                    1577  2015-07-04T00:00:00 to 2020-08-27T00:00:00\n",
      "S2_CLOUDCOVER_V200_FILE                  1577  2015-07-04T00:00:00 to 2020-08-27T00:00:00\n",
      "S2_FAPAR                                 1614  2015-07-04T00:00:00 to 2020-08-24T00:00:00\n",
      "S2_FAPAR_CLOUDCOVER                      1615  2015-07-04T00:00:00 to 2020-08-24T00:00:00\n",
      "S2_FAPAR_CLOUDCOVER_SC                   1615  2015-07-04T00:00:00 to 2020-08-24T00:00:00\n",
      "S2_FAPAR_FILE                            1577  2015-07-04T00:00:00 to 2020-08-27T00:00:00\n",
      "S2_FAPAR_V102_WEBMERCATOR2                595  2015-07-06T00:00:00 to 2018-10-10T00:00:00\n",
      "S2_FCOVER                                1523  2015-07-04T00:00:00 to 2020-06-16T00:00:00\n",
      "S2_LAI                                   1533  2015-07-04T00:00:00 to 2020-06-16T00:00:00\n",
      "S2_NDVI                                  1529  2015-07-04T00:00:00 to 2020-06-16T00:00:00\n",
      "S2_SCENECLASSIFICATION                   1615  2015-07-04T00:00:00 to 2020-08-24T00:00:00\n",
      "S2_SCENECLASSIFICATION_FILE              1577  2015-07-04T00:00:00 to 2020-08-27T00:00:00\n",
      "S2_SCENECLASSIFICATION_V200_FILE         1577  2015-07-04T00:00:00 to 2020-08-27T00:00:00\n",
      "SENTINEL2_FAPAR                           522  2016-01-15T00:00:00 to 2019-11-10T00:00:00\n",
      "SENTINEL2_FCOVER                          581  2016-01-02T00:00:00 to 2019-11-10T00:00:00\n",
      "SENTINEL2_LAI                             580  2016-01-02T00:00:00 to 2019-11-10T00:00:00\n",
      "SENTINEL2_NDVI                            569  2016-01-02T00:00:00 to 2019-11-10T00:00:00\n",
      "TERRASCOPE_S1_SLC_COHERENCE_V1_VH        6947  2016-09-26T00:00:00 to 2020-08-26T00:00:00\n",
      "TERRASCOPE_S1_SLC_COHERENCE_V1_VV        6947  2016-09-26T00:00:00 to 2020-08-26T00:00:00\n",
      "TERRASCOPE_S2_FAPAR_V2                   1577  2015-07-04T00:00:00 to 2020-08-27T00:00:00\n",
      "TERRASCOPE_S2_FCOVER_V2                  1577  2015-07-04T00:00:00 to 2020-08-27T00:00:00\n",
      "TERRASCOPE_S2_LAI_V2                     1577  2015-07-04T00:00:00 to 2020-08-27T00:00:00\n",
      "TERRASCOPE_S2_NDVI_V2                    1591  2015-07-04T00:00:00 to 2020-08-27T00:00:00\n",
      "VMM_CHL                                    47  2020-04-03T10:56:21 to 2020-07-26T10:40:31\n",
      "VMM_CLOUDCOVER                             47  2020-04-03T10:56:21 to 2020-07-26T10:40:31\n",
      "VMM_NDAVI                                  47  2020-04-03T10:56:21 to 2020-07-26T10:40:31\n",
      ">>> 81 layers with data\n",
      "Layers with no dates\n",
      "BELGIAN_COSTAL_ZONE_S2_NS_2017_RGB\n",
      "BELGIAN_COSTAL_ZONE_S2_NS_2017_SPM\n",
      "BIOPAR_BA300_V1_GLOBAL\n",
      "BIOPAR_FAPAR_V1_GLOBAL\n",
      "BIOPAR_FAPAR_V2_GLOBAL\n",
      "BIOPAR_FCOVER300_V1_GLOBAL\n",
      "BIOPAR_FCOVER_V1_GLOBAL\n",
      "BIOPAR_FCOVER_V2_GLOBAL\n",
      "BIOPAR_LAI300_V1_GLOBAL\n",
      "BIOPAR_LAI_V1_GLOBAL\n",
      "BIOPAR_LAI_V2_GLOBAL\n",
      "BIOPAR_NDVI300_V1_GLOBAL\n",
      "BIOPAR_NDVI_V2_GLOBAL\n",
      "BIOPAR_WB300_V1_GLOBAL\n",
      "DMC_FAPAR\n",
      "FSTEP_METEO_AVG_TEMPERATURE\n",
      "FSTEP_METEO_MAX_TEMPERATURE\n",
      "FSTEP_METEO_MIN_TEMPERATURE\n",
      "FSTEP_METEO_RAINFALL\n",
      "KIS_BALATON_MACROPHYTE_AWBIOM\n",
      "KIS_BALATON_MACROPHYTE_FCOVER\n",
      "LC8_MARKERMEER\n",
      "MANTUA_LAKES_CHLA_WFD\n",
      "MANTUA_LAKES_S2A_AWBIOM\n",
      "MANTUA_LAKES_S2A_FCOVER\n",
      "PO_RIVER_S2A_DOGLIOITTI\n",
      "PO_RIVER_TURBIDITY_L8\n",
      "S2_MARKERMEER\n",
      ">>> 28 layers without data\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for l in layersSorted:\n",
    "    if len(l['dates'])>0:\n",
    "        count=count+1\n",
    "        print(l['name'].ljust(40), '{0:4d} '.format(len(l['dates'])), min(l['dates'])[:19], 'to', max(l['dates'])[:19])\n",
    "print(\">>>\", count, 'layers with data')\n",
    "print('Layers with no dates')\n",
    "count=0\n",
    "for l in layersSorted:\n",
    "    if len(l['dates'])==0:\n",
    "        count=count+1\n",
    "        print(l['name'])\n",
    "print(\">>>\", count, 'layers without data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first extract the timeseries of a point, for all layers that have 'TERRASCOPE' in their name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TERRASCOPE_S1_SLC_COHERENCE_V1_VH',\n",
       " 'TERRASCOPE_S1_SLC_COHERENCE_V1_VV',\n",
       " 'TERRASCOPE_S2_FAPAR_V2',\n",
       " 'TERRASCOPE_S2_FCOVER_V2',\n",
       " 'TERRASCOPE_S2_LAI_V2',\n",
       " 'TERRASCOPE_S2_NDVI_V2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TSlayers = []\n",
    "for l in layersSorted:\n",
    "    if 'TERRASCOPE' in l['name']:\n",
    "        TSlayers.append(l['name'])\n",
    "TSlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeseriesForPoint(covId,tsvBaseURL='https://services.terrascope.be/timeseries/v1.0/ts/',\n",
    "                          start=datetime.date(2016,1,1),end=datetime.date(2030,12,31),\n",
    "                          lat=51.146,lon=3.682,printURL=False):\n",
    "\n",
    "    tsURL = tsvBaseURL + covId + '/point'\n",
    "    payload = {\n",
    "            'lon': str(lon),\n",
    "            'lat': str(lat),\n",
    "            'startDate': start.strftime('%Y-%m-%d'),\n",
    "            'endDate': end.strftime('%Y-%m-%d')\n",
    "    }\n",
    "    if printURL:\n",
    "        print(tsURL,payload)\n",
    "    response=requests.get(tsURL,params=payload)\n",
    "    if response.status_code == 200:\n",
    "        timeseries = response.json()['results']\n",
    "        return(timeseries)\n",
    "    else:\n",
    "        return([])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer                                    points\n",
      "---------------------------------------  ------\n",
      "TERRASCOPE_S1_SLC_COHERENCE_V1_VH             0\n",
      "TERRASCOPE_S1_SLC_COHERENCE_V1_VV             0\n",
      "TERRASCOPE_S2_FAPAR_V2                       97\n",
      "TERRASCOPE_S2_FCOVER_V2                      97\n",
      "TERRASCOPE_S2_LAI_V2                         97\n",
      "TERRASCOPE_S2_NDVI_V2                        97\n"
     ]
    }
   ],
   "source": [
    "print('layer'.ljust(40), 'points')\n",
    "print('---------------------------------------  ------')\n",
    "for l in TSlayers:\n",
    "    ts = getTimeseriesForPoint(covId=l,start=datetime.date(2020,1,1), end = datetime.date(2020,7,1), printURL=False)\n",
    "    print(l.ljust(40),'{0:6d}'.format(len(ts)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are no results for coherence. This needs further analysis.<br>\n",
    "<br>\n",
    "Let's have a look at the last time series that we have extracted, for NDVI.<br>\n",
    "We'll only list the points that are valid (all others cannot be determined due to cloud cover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date        average\n",
      "----------  -------\n",
      "2020-01-01   0.2360\n",
      "2020-01-04   0.3240\n",
      "2020-01-06   0.3200\n",
      "2020-01-19   0.3640\n",
      "2020-01-26   0.3320\n",
      "2020-02-13   0.4080\n",
      "2020-03-19   0.4880\n",
      "2020-03-21   0.5160\n",
      "2020-03-24   0.5080\n",
      "2020-03-26   0.5080\n",
      "2020-03-31   0.5000\n",
      "2020-04-05   0.5600\n",
      "2020-04-08   0.6000\n",
      "2020-04-10   0.5960\n",
      "2020-04-13   0.7040\n",
      "2020-04-20   0.7760\n",
      "2020-04-23   0.7960\n",
      "2020-04-25   0.7840\n",
      "2020-05-05   0.8800\n",
      "2020-05-15   0.8760\n",
      "2020-05-18   0.8800\n",
      "2020-05-20   0.8280\n",
      "2020-05-23   0.8520\n",
      "2020-05-25   0.8800\n",
      "2020-05-28   0.9160\n",
      "2020-05-30   0.8800\n",
      "2020-06-07   0.8480\n",
      "2020-06-22   0.6080\n",
      "2020-06-24   0.8760\n"
     ]
    }
   ],
   "source": [
    "print('date        average')\n",
    "print('----------  -------')\n",
    "for d in ts:\n",
    "    if d['result']['validCount']>0:\n",
    "        print(d['date'], '  {0:.4f}'.format(d['result']['average']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On to time series for a polygon then. <br>\n",
    "This is done using a POST request, rather than a GET request for a point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeseriesForPolygon(covId, polylist,\n",
    "                            tsvBaseURL='https://services.terrascope.be/timeseries/v1.0/ts/',\n",
    "                            start=datetime.date(2016,1,1),end=datetime.date(2030,12,31),\n",
    "                            printURL=False):\n",
    "\n",
    "\n",
    "    tsURL = tsvBaseURL + covId \n",
    "    # print(tsvURL)\n",
    "    tsURL = tsURL +'/geometry'\n",
    "\n",
    "    payload = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "            \"type\": \"Polygon\",\n",
    "            \"coordinates\": [\n",
    "            \n",
    "                polylist\n",
    "            \n",
    "            ]\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "#    payload['startDate'] = start.strftime('%Y-%m-%d')\n",
    "#    payload['endDate'] = end.strftime('%Y-%m-%d')\n",
    "    if printURL:\n",
    "        print(tsURL, payload)\n",
    "    response=requests.post(url=tsURL,json=payload, params={'startDate':start.strftime('%Y-%m-%d'), 'endDate':end.strftime('%Y-%m-%d')})\n",
    "\n",
    "    if response.status_code==200:\n",
    "        timeSeries = response.json()['results']   \n",
    "        return(timeSeries)\n",
    "    else:\n",
    "        return([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon=[]\n",
    "\n",
    "point = [3.65, 51.14]\n",
    "polygon.append(point)\n",
    "point = [3.66, 51.14]\n",
    "polygon.append(point)\n",
    "point = [3.66, 51.15]\n",
    "polygon.append(point)\n",
    "point = [3.65, 51.15]\n",
    "polygon.append(point)\n",
    "point = [3.65, 51.14]\n",
    "polygon.append(point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TERRASCOPE_S1_SLC_COHERENCE_V1_VH 86\n",
      "TERRASCOPE_S1_SLC_COHERENCE_V1_VV 86\n",
      "TERRASCOPE_S2_FAPAR_V2 64\n",
      "TERRASCOPE_S2_FCOVER_V2 64\n",
      "TERRASCOPE_S2_LAI_V2 64\n",
      "TERRASCOPE_S2_NDVI_V2 64\n"
     ]
    }
   ],
   "source": [
    "PolyResults=[]\n",
    "for l in TSlayers:\n",
    "    Tresult={}\n",
    "    Tresult['name']=l\n",
    "    Tresult['series']= getTimeseriesForPolygon(covId=l,polylist=polygon, start = datetime.date(2020,1,1), end = datetime.date(2020,5,1),printURL=False)\n",
    "    PolyResults.append(Tresult)\n",
    "    print(Tresult['name'], len(Tresult['series']))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's print the time series.<Br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TERRASCOPE_S2_FCOVER_V2\n",
      "date        total  valid   ratio average\n",
      "---------- ------ ------  ------ -------\n",
      "2020-01-04  21576  21142  0.9799  0.2861\n",
      "2020-01-06  21576  21098  0.9778  0.3124\n",
      "2020-01-19  21576  21418  0.9927  0.3382\n",
      "2020-01-26  21576  21458  0.9945  0.2457\n",
      "2020-03-19  21576  21338  0.9890  0.3927\n",
      "2020-03-21  21576  21368  0.9904  0.4822\n",
      "2020-03-24  21576  21576  1.0000  0.4615\n",
      "2020-03-26  21576  21576  1.0000  0.4331\n",
      "2020-03-31  21576  21377  0.9908  0.4588\n",
      "2020-04-05  21576  21576  1.0000  0.4650\n",
      "2020-04-08  21576  21576  1.0000  0.4645\n",
      "2020-04-10  21576  21576  1.0000  0.4592\n",
      "2020-04-13  21576  20333  0.9424  0.4772\n",
      "2020-04-20  21576  21576  1.0000  0.5071\n",
      "2020-04-23  21576  21474  0.9953  0.5232\n",
      "2020-04-25  21576  20585  0.9541  0.5155\n"
     ]
    }
   ],
   "source": [
    "ind=3\n",
    "print(PolyResults[ind]['name'])\n",
    "print('date'.ljust(11), 'total', ' valid', '  ratio','average')\n",
    "print('---------- ------ ------  ------ -------')\n",
    "cutoff=0.9\n",
    "\n",
    "\n",
    "for r in PolyResults[ind]['series']:\n",
    "    if r['result']['validCount']/r['result']['totalCount'] > cutoff:\n",
    "        print(r['date'], '{0:6d}'.format(r['result']['totalCount']), '{0:6d}'.format(r['result']['validCount']), \n",
    "              ' {0:.4f}'.format(r['result']['validCount']/r['result']['totalCount']), ' {0:.4f}'.format(r['result']['average']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is okay: \n",
    "- the total number is the number of pixels in the polygon; it is constant, because the polygon doesn't change.\n",
    "- the valid number is the number of pixels that are not covered by clouds. We are just printing the measures that have 90% good pixels\n",
    "- the ratio is valid/total\n",
    "- average is the value of the indicator at that date averaged over all pixels\n",
    "<br>\n",
    "No, let's have a look at the coherence time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TERRASCOPE_S1_SLC_COHERENCE_V1_VV\n",
      "date        total  valid   ratio average\n",
      "---------- ------ ------  ------ -------\n",
      "2020-01-03  86304  86304  1.0000  0.6427\n",
      "2020-01-05 194184 186012  0.9579  0.5306\n",
      "2020-01-09  86304  86304  1.0000  0.5806\n",
      "2020-01-11 194184 194184  1.0000  0.6472\n",
      "2020-01-15  86304  86304  1.0000  0.5739\n",
      "2020-01-18 107880 107880  1.0000  0.6755\n",
      "2020-01-21  86304  86304  1.0000  0.4931\n",
      "2020-01-23 194184 194184  1.0000  0.6512\n",
      "2020-01-24 107880 107880  1.0000  0.5771\n",
      "2020-01-27  86304  86304  1.0000  0.6815\n",
      "2020-01-30 107880 107880  1.0000  0.5065\n",
      "2020-02-02  86304  86304  1.0000  0.6408\n",
      "2020-02-05 107880 107880  1.0000  0.4870\n",
      "2020-02-08  86304  86304  1.0000  0.6229\n",
      "2020-02-10 194184 187659  0.9664  0.5236\n",
      "2020-02-11 107880 107880  1.0000  0.4499\n",
      "2020-02-14  86304  86304  1.0000  0.5887\n",
      "2020-02-16 194184 193167  0.9948  0.5098\n",
      "2020-02-17 107880 107880  1.0000  0.3991\n",
      "2020-02-20  86304  86304  1.0000  0.6385\n",
      "2020-02-22 194184 190674  0.9819  0.5490\n",
      "2020-02-23 107880 107880  1.0000  0.4651\n",
      "2020-02-26  86304  86304  1.0000  0.3891\n",
      "2020-02-28 194184 194184  1.0000  0.5080\n",
      "2020-02-29 107880 107880  1.0000  0.5832\n",
      "2020-03-03  86304  86304  1.0000  0.3984\n",
      "2020-03-05 194184 189144  0.9740  0.4169\n",
      "2020-03-06 107880 107880  1.0000  0.6106\n",
      "2020-03-09  86304  86304  1.0000  0.4427\n",
      "2020-03-11 194184 194184  1.0000  0.3889\n",
      "2020-03-12 107880 107880  1.0000  0.4645\n",
      "2020-03-15  86304  86304  1.0000  0.4569\n",
      "2020-03-17 194184 177939  0.9163  0.4932\n",
      "2020-03-18 107880 107880  1.0000  0.5122\n",
      "2020-03-21  86304  86304  1.0000  0.5469\n",
      "2020-03-23 194184 194184  1.0000  0.4050\n",
      "2020-03-24 107880 107880  1.0000  0.4499\n",
      "2020-03-27  86304  86304  1.0000  0.4030\n",
      "2020-03-29 194184 183303  0.9440  0.5463\n",
      "2020-03-30 107880 107880  1.0000  0.5716\n",
      "2020-04-02  86304  86304  1.0000  0.5954\n",
      "2020-04-04 194184 194184  1.0000  0.4281\n",
      "2020-04-05 107880 107880  1.0000  0.4817\n",
      "2020-04-08  86304  86304  1.0000  0.5257\n",
      "2020-04-10 194184 192600  0.9918  0.4617\n",
      "2020-04-11 107880 107880  1.0000  0.3987\n",
      "2020-04-14  86304  86304  1.0000  0.4459\n",
      "2020-04-16 194184 194184  1.0000  0.3685\n",
      "2020-04-17 107880 107880  1.0000  0.4048\n",
      "2020-04-20  86304  86304  1.0000  0.3683\n",
      "2020-04-22 194184 194184  1.0000  0.4284\n",
      "2020-04-23 107880 107880  1.0000  0.4454\n",
      "2020-04-26  86304  86304  1.0000  0.3455\n",
      "2020-04-28 194184 194184  1.0000  0.3694\n",
      "2020-04-29 107880 107880  1.0000  0.3878\n"
     ]
    }
   ],
   "source": [
    "ind=1\n",
    "print(PolyResults[ind]['name'])\n",
    "print('date'.ljust(11), 'total', ' valid', '  ratio','average')\n",
    "print('---------- ------ ------  ------ -------')\n",
    "cutoff=0.9\n",
    "\n",
    "for r in PolyResults[ind]['series']:\n",
    "    if r['result']['validCount']/r['result']['totalCount'] > cutoff:\n",
    "        print(r['date'], '{0:6d}'.format(r['result']['totalCount']), '{0:6d}'.format(r['result']['validCount']), \n",
    "              ' {0:.4f}'.format(r['result']['validCount']/r['result']['totalCount']), ' {0:.4f}'.format(r['result']['average']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is strange: \n",
    "- the total number is the number of pixels in the polygon; it is <b>not</b> constant, probably because there are multiple entries per date in the time series.\n",
    "- the valid number is <b>not</b> constant and equal to total. As RADAR is cloud penetrating, there's no reason for pixels to be invalid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
