{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Timeseries demo\n",
    "<br>\n",
    "There's two ways to extract a time series: for a point or for a polygon. There's an example for both below. <br>\n",
    "If you prefer a GUI, then check out [https://viewer.terrascope.be/], and go to <b>Area of Interest</b>. <br>\n",
    "When you use this Notebook, you have access to more layers than in the GUI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "tsvBaseURL='https://services.terrascope.be/timeseries/v1.0/ts/'\n",
    "\n",
    "response = requests.get(tsvBaseURL) #this returns the layers that are available\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.status_code == 200:\n",
    "    layerlist = response.json()['layers']\n",
    "else:\n",
    "    raise IOError(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's investigate the layers that are offered. The list is not sorted, so let's sort it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "layersSorted = sorted(layerlist, key=lambda k: k['name']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOPAR_FAPAR300_V1_GLOBAL                 129  2013-10-16T00:00:00 to 2017-05-04T00:00:00\n",
      "CGLS_LC100_COV_LCCS                      1598  2015-07-04T00:00:00 to 2020-08-08T00:00:00\n",
      "CHIRPS_RAINFALL                           792  1998-01-11T00:00:00 to 2020-07-21T00:00:00\n",
      "DCS4COP_CHL_V103                          799  2016-01-02T10:54:42 to 2020-05-30T12:27:01\n",
      "DCS4COP_CLOUDCOVER_V103                   810  2016-01-02T10:54:42 to 2020-05-30T12:27:01\n",
      "DCS4COP_FLANDERS_CHL                      454  2017-01-02T11:14:42 to 2018-10-31T11:02:01\n",
      "DCS4COP_FLANDERS_CHL_V100                 750  2017-01-02T11:14:42 to 2020-02-10T10:52:01\n",
      "DCS4COP_FLANDERS_CHL_V102                 890  2017-01-02T11:14:42 to 2020-06-02T10:56:31\n",
      "DCS4COP_FLANDERS_CLOUDCOVER               454  2017-01-02T11:14:42 to 2018-10-31T11:02:01\n",
      "DCS4COP_FLANDERS_CLOUDCOVER_L8            159  2017-01-03T10:40:38 to 2018-08-27T10:33:22\n",
      "DCS4COP_FLANDERS_CLOUDCOVER_L8_V100        38  2019-05-10T10:30:59 to 2019-05-31T10:53:42\n",
      "DCS4COP_FLANDERS_CLOUDCOVER_V100          927  2017-01-02T11:14:42 to 2020-02-10T11:43:49\n",
      "DCS4COP_FLANDERS_CLOUDCOVER_V102          894  2017-01-02T11:14:42 to 2020-06-02T10:56:31\n",
      "DCS4COP_FLANDERS_SPM                      454  2017-01-02T11:14:42 to 2018-10-31T11:02:01\n",
      "DCS4COP_FLANDERS_SPM_L8                   159  2017-01-03T10:40:38 to 2018-08-27T10:33:22\n",
      "DCS4COP_FLANDERS_SPM_V100                 748  2017-01-02T11:14:42 to 2020-02-10T10:52:01\n",
      "DCS4COP_FLANDERS_SPM_V102                 890  2017-01-02T11:14:42 to 2020-06-02T10:56:31\n",
      "DCS4COP_FLANDERS_TUR                      454  2017-01-02T11:14:42 to 2018-10-31T11:02:01\n",
      "DCS4COP_FLANDERS_TUR_L8                   159  2017-01-03T10:40:38 to 2018-08-27T10:33:22\n",
      "DCS4COP_FLANDERS_TUR_V100                 749  2017-01-02T11:14:42 to 2020-02-10T10:52:01\n",
      "DCS4COP_FLANDERS_TUR_V102                 891  2017-01-02T11:14:42 to 2020-06-02T10:56:31\n",
      "DCS4COP_NDAVI_V103                          4  2020-05-29T11:21:21 to 2020-05-30T12:27:01\n",
      "DCS4COP_SPM_V103                          727  2016-01-02T00:00:00 to 2020-06-16T00:00:00\n",
      "DCS4COP_TUR_V103                          727  2016-01-02T00:00:00 to 2020-06-16T00:00:00\n",
      "FSTEP_SENTINEL2_FAPAR                     150  2016-01-05T00:00:00 to 2019-02-08T00:00:00\n",
      "FSTEP_SENTINEL2_FAPAR_MASK                154  2016-01-05T00:00:00 to 2019-02-08T00:00:00\n",
      "FSTEP_SENTINEL2_FCOVER                    149  2016-01-05T00:00:00 to 2019-02-08T00:00:00\n",
      "FSTEP_SENTINEL2_FCOVER_MASK               154  2016-01-05T00:00:00 to 2019-02-08T00:00:00\n",
      "FSTEP_SENTINEL2_LAI                       149  2016-01-05T00:00:00 to 2019-02-08T00:00:00\n",
      "FSTEP_SENTINEL2_LAI_MASK                  154  2016-01-05T00:00:00 to 2019-02-08T00:00:00\n",
      "FSTEP_SENTINEL2_NDVI                      149  2016-01-05T00:00:00 to 2019-02-08T00:00:00\n",
      "FSTEP_SENTINEL2_NDVI_MASK                 154  2016-01-05T00:00:00 to 2019-02-08T00:00:00\n",
      "FSTEP_WEEKLY_METEO_AVG_TEMPERATURE        111  2016-01-01T00:00:00 to 2018-02-05T00:00:00\n",
      "FSTEP_WEEKLY_METEO_RAINFALL               109  2016-01-01T08:00:00 to 2018-01-22T08:00:00\n",
      "PROBAV_L3_S10_TOC_NDVI_333M               246  2013-10-11T00:00:00 to 2020-08-01T00:00:00\n",
      "S1_GRD_GAMMA0_ASCENDING_ANGLE             780  2015-01-03T00:00:00 to 2020-06-15T00:00:00\n",
      "S1_GRD_GAMMA0_ASCENDING_VH                780  2015-01-03T00:00:00 to 2020-06-15T00:00:00\n",
      "S1_GRD_GAMMA0_ASCENDING_VV                780  2015-01-03T00:00:00 to 2020-06-15T00:00:00\n",
      "S1_GRD_GAMMA0_DESCENDING_ANGLE           1043  2015-01-07T00:00:00 to 2020-06-15T00:00:00\n",
      "S1_GRD_GAMMA0_DESCENDING_VH              1043  2015-01-07T00:00:00 to 2020-06-15T00:00:00\n",
      "S1_GRD_GAMMA0_DESCENDING_VV              1043  2015-01-07T00:00:00 to 2020-06-15T00:00:00\n",
      "S1_GRD_GAMMA0_VH                         1779  2015-01-03T00:00:00 to 2020-08-20T00:00:00\n",
      "S1_GRD_GAMMA0_VV                         1779  2015-01-03T00:00:00 to 2020-08-20T00:00:00\n",
      "S1_GRD_SIGMA0_ASCENDING_ANGLE             780  2015-01-03T00:00:00 to 2020-06-15T00:00:00\n",
      "S1_GRD_SIGMA0_ASCENDING_VH                780  2015-01-03T00:00:00 to 2020-06-15T00:00:00\n",
      "S1_GRD_SIGMA0_ASCENDING_VV                780  2015-01-03T00:00:00 to 2020-06-15T00:00:00\n",
      "S1_GRD_SIGMA0_DESCENDING_ANGLE           1043  2015-01-07T00:00:00 to 2020-06-15T00:00:00\n",
      "S1_GRD_SIGMA0_DESCENDING_VH              1043  2015-01-07T00:00:00 to 2020-06-15T00:00:00\n",
      "S1_GRD_SIGMA0_DESCENDING_VV              1043  2015-01-07T00:00:00 to 2020-06-15T00:00:00\n",
      "S2_CLOUDCOVER_GLOBAL                     1570  2015-07-04T00:00:00 to 2020-08-20T00:00:00\n",
      "S2_CLOUDCOVER_GLOBAL2                    1570  2015-07-04T00:00:00 to 2020-08-20T00:00:00\n",
      "S2_CLOUDCOVER_V200_FILE                  1570  2015-07-04T00:00:00 to 2020-08-20T00:00:00\n",
      "S2_FAPAR                                 1598  2015-07-04T00:00:00 to 2020-08-08T00:00:00\n",
      "S2_FAPAR_CLOUDCOVER                      1611  2015-07-04T00:00:00 to 2020-08-20T00:00:00\n",
      "S2_FAPAR_CLOUDCOVER_SC                   1611  2015-07-04T00:00:00 to 2020-08-20T00:00:00\n",
      "S2_FAPAR_FILE                            1570  2015-07-04T00:00:00 to 2020-08-20T00:00:00\n",
      "S2_FAPAR_V102_WEBMERCATOR2                595  2015-07-06T00:00:00 to 2018-10-10T00:00:00\n",
      "S2_FCOVER                                1523  2015-07-04T00:00:00 to 2020-06-16T00:00:00\n",
      "S2_LAI                                   1533  2015-07-04T00:00:00 to 2020-06-16T00:00:00\n",
      "S2_NDVI                                  1529  2015-07-04T00:00:00 to 2020-06-16T00:00:00\n",
      "S2_SCENECLASSIFICATION                   1611  2015-07-04T00:00:00 to 2020-08-20T00:00:00\n",
      "S2_SCENECLASSIFICATION_FILE              1570  2015-07-04T00:00:00 to 2020-08-20T00:00:00\n",
      "S2_SCENECLASSIFICATION_V200_FILE         1570  2015-07-04T00:00:00 to 2020-08-20T00:00:00\n",
      "SENTINEL2_FAPAR                           522  2016-01-15T00:00:00 to 2019-11-10T00:00:00\n",
      "SENTINEL2_FCOVER                          581  2016-01-02T00:00:00 to 2019-11-10T00:00:00\n",
      "SENTINEL2_LAI                             580  2016-01-02T00:00:00 to 2019-11-10T00:00:00\n",
      "SENTINEL2_NDVI                            569  2016-01-02T00:00:00 to 2019-11-10T00:00:00\n",
      "TERRASCOPE_S1_SLC_COHERENCE_V1_VH        6925  2016-09-26T00:00:00 to 2020-08-20T00:00:00\n",
      "TERRASCOPE_S1_SLC_COHERENCE_V1_VV        6925  2016-09-26T00:00:00 to 2020-08-20T00:00:00\n",
      "TERRASCOPE_S2_FAPAR_V2                   1570  2015-07-04T00:00:00 to 2020-08-20T00:00:00\n",
      "TERRASCOPE_S2_FCOVER_V2                  1570  2015-07-04T00:00:00 to 2020-08-20T00:00:00\n",
      "TERRASCOPE_S2_LAI_V2                     1570  2015-07-04T00:00:00 to 2020-08-20T00:00:00\n",
      "TERRASCOPE_S2_NDVI_V2                    1584  2015-07-04T00:00:00 to 2020-08-20T00:00:00\n",
      "VMM_CHL                                    47  2020-04-03T10:56:21 to 2020-07-26T10:40:31\n",
      "VMM_CLOUDCOVER                             47  2020-04-03T10:56:21 to 2020-07-26T10:40:31\n",
      "VMM_NDAVI                                  47  2020-04-03T10:56:21 to 2020-07-26T10:40:31\n",
      ">>> 76 layers with data\n",
      "Layers with no dates\n",
      "BELGIAN_COSTAL_ZONE_S2_NS_2017_RGB\n",
      "BELGIAN_COSTAL_ZONE_S2_NS_2017_SPM\n",
      "BIOPAR_BA300_V1_GLOBAL\n",
      "BIOPAR_FAPAR_V1_GLOBAL\n",
      "BIOPAR_FAPAR_V2_GLOBAL\n",
      "BIOPAR_FCOVER300_V1_GLOBAL\n",
      "BIOPAR_FCOVER_V1_GLOBAL\n",
      "BIOPAR_FCOVER_V2_GLOBAL\n",
      "BIOPAR_LAI300_V1_GLOBAL\n",
      "BIOPAR_LAI_V1_GLOBAL\n",
      "BIOPAR_LAI_V2_GLOBAL\n",
      "BIOPAR_NDVI300_V1_GLOBAL\n",
      "BIOPAR_NDVI_V2_GLOBAL\n",
      "BIOPAR_WB300_V1_GLOBAL\n",
      "DMC_FAPAR\n",
      "FSTEP_METEO_AVG_TEMPERATURE\n",
      "FSTEP_METEO_MAX_TEMPERATURE\n",
      "FSTEP_METEO_MIN_TEMPERATURE\n",
      "FSTEP_METEO_RAINFALL\n",
      "KIS_BALATON_MACROPHYTE_AWBIOM\n",
      "KIS_BALATON_MACROPHYTE_FCOVER\n",
      "LC8_MARKERMEER\n",
      "MANTUA_LAKES_CHLA_WFD\n",
      "MANTUA_LAKES_S2A_AWBIOM\n",
      "MANTUA_LAKES_S2A_FCOVER\n",
      "PO_RIVER_S2A_DOGLIOITTI\n",
      "PO_RIVER_TURBIDITY_L8\n",
      "S2_MARKERMEER\n",
      ">>> 28 layers without data\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for l in layersSorted:\n",
    "    if len(l['dates'])>0:\n",
    "        count=count+1\n",
    "        print(l['name'].ljust(40), '{0:4d} '.format(len(l['dates'])), min(l['dates'])[:19], 'to', max(l['dates'])[:19])\n",
    "print(\">>>\", count, 'layers with data')\n",
    "print('Layers with no dates')\n",
    "count=0\n",
    "for l in layersSorted:\n",
    "    if len(l['dates'])==0:\n",
    "        count=count+1\n",
    "        print(l['name'])\n",
    "print(\">>>\", count, 'layers without data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first extract the timeseries of a point, for all layers that have 'TERRASCOPE' in their name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TERRASCOPE_S1_SLC_COHERENCE_V1_VH',\n",
       " 'TERRASCOPE_S1_SLC_COHERENCE_V1_VV',\n",
       " 'TERRASCOPE_S2_FAPAR_V2',\n",
       " 'TERRASCOPE_S2_FCOVER_V2',\n",
       " 'TERRASCOPE_S2_LAI_V2',\n",
       " 'TERRASCOPE_S2_NDVI_V2']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TSlayers = []\n",
    "for l in layersSorted:\n",
    "    if 'TERRASCOPE' in l['name']:\n",
    "        TSlayers.append(l['name'])\n",
    "TSlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeseriesForPoint(covId,tsvBaseURL='https://services.terrascope.be/timeseries/v1.0/ts/',\n",
    "                          start=datetime.date(2016,1,1),end=datetime.date(2030,12,31),\n",
    "                          lat=51.146,lon=3.682,printURL=False):\n",
    "\n",
    "    tsURL = tsvBaseURL + covId + '/point'\n",
    "    payload = {\n",
    "            'lon': str(lon),\n",
    "            'lat': str(lat),\n",
    "            'startDate': start.strftime('%Y-%m-%d'),\n",
    "            'endDate': end.strftime('%Y-%m-%d')\n",
    "    }\n",
    "    if printURL:\n",
    "        print(tsURL,payload)\n",
    "    response=requests.get(tsURL,params=payload)\n",
    "    if response.status_code == 200:\n",
    "        timeseries = response.json()['results']\n",
    "        return(timeseries)\n",
    "    else:\n",
    "        return([])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer                                    points\n",
      "---------------------------------------  ------\n",
      "TERRASCOPE_S1_SLC_COHERENCE_V1_VH             0\n",
      "TERRASCOPE_S1_SLC_COHERENCE_V1_VV             0\n",
      "TERRASCOPE_S2_FAPAR_V2                       97\n",
      "TERRASCOPE_S2_FCOVER_V2                      97\n",
      "TERRASCOPE_S2_LAI_V2                         97\n",
      "TERRASCOPE_S2_NDVI_V2                        97\n"
     ]
    }
   ],
   "source": [
    "print('layer'.ljust(40), 'points')\n",
    "print('---------------------------------------  ------')\n",
    "for l in TSlayers:\n",
    "    ts = getTimeseriesForPoint(covId=l,start=datetime.date(2020,1,1), end = datetime.date(2020,7,1), printURL=False)\n",
    "    print(l.ljust(40),'{0:6d}'.format(len(ts)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are no results for coherence. This needs further analysis.<br>\n",
    "<br>\n",
    "Let's have a look at the last time series that we have extracted, for NDVI.<br>\n",
    "We'll only list the points that are valid (all others cannot be determined due to cloud cover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date        average\n",
      "----------  -------\n",
      "2020-01-01   0.2360\n",
      "2020-01-04   0.3240\n",
      "2020-01-06   0.3200\n",
      "2020-01-19   0.3640\n",
      "2020-01-26   0.3320\n",
      "2020-02-13   0.4080\n",
      "2020-03-19   0.4880\n",
      "2020-03-21   0.5160\n",
      "2020-03-24   0.5080\n",
      "2020-03-26   0.5080\n",
      "2020-03-31   0.5000\n",
      "2020-04-05   0.5600\n",
      "2020-04-08   0.6000\n",
      "2020-04-10   0.5960\n",
      "2020-04-13   0.7040\n",
      "2020-04-20   0.7760\n",
      "2020-04-23   0.7960\n",
      "2020-04-25   0.7840\n",
      "2020-05-05   0.8800\n",
      "2020-05-15   0.8760\n",
      "2020-05-18   0.8800\n",
      "2020-05-20   0.8280\n",
      "2020-05-23   0.8520\n",
      "2020-05-25   0.8800\n",
      "2020-05-28   0.9160\n",
      "2020-05-30   0.8800\n",
      "2020-06-07   0.8480\n",
      "2020-06-22   0.6080\n",
      "2020-06-24   0.8760\n"
     ]
    }
   ],
   "source": [
    "print('date        average')\n",
    "print('----------  -------')\n",
    "for d in ts:\n",
    "    if d['result']['validCount']>0:\n",
    "        print(d['date'], '  {0:.4f}'.format(d['result']['average']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On to time series for a polygon then. <br>\n",
    "This is done using a POST request, rather than a GET request for a point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeseriesForPolygon(covId, polylist,\n",
    "                            tsvBaseURL='https://services.terrascope.be/timeseries/v1.0/ts/',\n",
    "                            start=datetime.date(2016,1,1),end=datetime.date(2030,12,31),\n",
    "                            printURL=False):\n",
    "\n",
    "\n",
    "    tsURL = tsvBaseURL + covId \n",
    "    # print(tsvURL)\n",
    "    tsURL = tsURL +'/geometry'\n",
    "\n",
    "    payload = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "            \"type\": \"Polygon\",\n",
    "            \"coordinates\": [\n",
    "            \n",
    "                polylist\n",
    "            \n",
    "            ]\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "    payload['startDate'] = start.strftime('%Y-%m-%d')\n",
    "    payload['endDate'] = end.strftime('%Y-%m-%d')\n",
    "    if printURL:\n",
    "        print(tsURL, payload)\n",
    "    response=requests.post(url=tsURL,json=payload)\n",
    "\n",
    "    if response.status_code==200:\n",
    "        timeSeries = response.json()['results']   \n",
    "        return(timeSeries)\n",
    "    else:\n",
    "        return([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon=[]\n",
    "\n",
    "point = [3.65, 51.14]\n",
    "polygon.append(point)\n",
    "point = [3.66, 51.14]\n",
    "polygon.append(point)\n",
    "point = [3.66, 51.15]\n",
    "polygon.append(point)\n",
    "point = [3.65, 51.15]\n",
    "polygon.append(point)\n",
    "point = [3.65, 51.14]\n",
    "polygon.append(point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TERRASCOPE_S1_SLC_COHERENCE_V1_VH 1036\n",
      "TERRASCOPE_S1_SLC_COHERENCE_V1_VV 1036\n",
      "TERRASCOPE_S2_FAPAR_V2 839\n",
      "TERRASCOPE_S2_FCOVER_V2 839\n",
      "TERRASCOPE_S2_LAI_V2 839\n",
      "TERRASCOPE_S2_NDVI_V2 839\n"
     ]
    }
   ],
   "source": [
    "PolyResults=[]\n",
    "for l in TSlayers:\n",
    "    Tresult={}\n",
    "    Tresult['name']=l\n",
    "    Tresult['series']= getTimeseriesForPolygon(covId=l,polylist=polygon, start = datetime.date(2020,1,1), end = datetime.date(2020,5,1),printURL=False)\n",
    "    PolyResults.append(Tresult)\n",
    "    print(Tresult['name'], len(Tresult['series']))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The start and end date are not taken into account, So, we'll print just the start of the time series.<Br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TERRASCOPE_S2_FCOVER_V2\n",
      "date        total  valid   ratio average\n",
      "---------- ------ ------  ------ -------\n",
      "2015-07-06  21576  20566  0.9532  0.5671\n",
      "2015-07-16  21576  21576  1.0000  0.5454\n",
      "2015-12-03  21576  21260  0.9854  0.3427\n",
      "2016-01-25  21576  20752  0.9618  0.3933\n",
      "2016-03-12  21576  21576  1.0000  0.4106\n",
      "2016-03-15  21576  21563  0.9994  0.3901\n",
      "2016-04-01  21576  21345  0.9893  0.4722\n",
      "2016-04-04  21576  20997  0.9732  0.4566\n",
      "2016-04-14  21576  20997  0.9732  0.3950\n",
      "2016-05-01  21576  21227  0.9838  0.5496\n",
      "2016-05-04  21576  21250  0.9849  0.5605\n",
      "2016-05-11  21576  20492  0.9498  0.4479\n",
      "2016-06-23  21576  21519  0.9974  0.5479\n",
      "2016-07-03  21576  21461  0.9947  0.5571\n",
      "2016-07-20  21576  21330  0.9886  0.5140\n",
      "2016-09-08  21576  21340  0.9891  0.5041\n",
      "2016-09-21  21576  21576  1.0000  0.4320\n",
      "2016-09-28  21576  21548  0.9987  0.3785\n",
      "2016-10-01  21576  20247  0.9384  0.3068\n",
      "2016-10-08  21576  19955  0.9249  0.3534\n",
      "2016-10-11  21576  21084  0.9772  0.2092\n",
      "2016-10-21  21576  19645  0.9105  0.2491\n",
      "2016-10-31  21576  21491  0.9961  0.3581\n",
      "2016-12-20  21576  21528  0.9978  0.1819\n",
      "2016-12-27  21576  20823  0.9651  0.3146\n"
     ]
    }
   ],
   "source": [
    "ind=3\n",
    "print(PolyResults[ind]['name'])\n",
    "print('date'.ljust(11), 'total', ' valid', '  ratio','average')\n",
    "print('---------- ------ ------  ------ -------')\n",
    "cutoff=0.9\n",
    "count=0\n",
    "maxcount=25\n",
    "for r in PolyResults[ind]['series']:\n",
    "    if r['result']['validCount']/r['result']['totalCount'] > cutoff and count<maxcount:\n",
    "        print(r['date'], '{0:6d}'.format(r['result']['totalCount']), '{0:6d}'.format(r['result']['validCount']), \n",
    "              ' {0:.4f}'.format(r['result']['validCount']/r['result']['totalCount']), ' {0:.4f}'.format(r['result']['average']))\n",
    "        count=count+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is okay: \n",
    "- the total number is the number of pixels in the polygon; it is constant, because the polygon doesn't change.\n",
    "- the valid number is the number of pixels that are not covered by clouds. We are just printing the measures that have 90% good pixels\n",
    "- the ratio is valid/total\n",
    "- average is the value of the indicator at that date averaged over all pixels\n",
    "<br>\n",
    "No, let's have a look at the coherence time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TERRASCOPE_S1_SLC_COHERENCE_V1_VV\n",
      "date        total  valid   ratio average\n",
      "---------- ------ ------  ------ -------\n",
      "2016-09-26  64728  64728  1.0000  0.4301\n",
      "2016-09-29 107880 107880  1.0000  0.3240\n",
      "2016-10-02  64728  64728  1.0000  0.3393\n",
      "2016-10-04 172608 172520  0.9995  0.4023\n",
      "2016-10-05 107880 107880  1.0000  0.3902\n",
      "2016-10-08 107880 107880  1.0000  0.3969\n",
      "2016-10-10  86304  86264  0.9995  0.3651\n",
      "2016-10-11 107880 107880  1.0000  0.4649\n",
      "2016-10-14 107880 107880  1.0000  0.3864\n",
      "2016-10-16  86304  86304  1.0000  0.4627\n",
      "2016-10-17 107880 107880  1.0000  0.3909\n",
      "2016-10-20 107880 107880  1.0000  0.3239\n",
      "2016-10-22  86304  85392  0.9894  0.4233\n",
      "2016-10-23 107880 107880  1.0000  0.4000\n",
      "2016-10-26  86304  86304  1.0000  0.3800\n",
      "2016-10-28  86304  85644  0.9924  0.5507\n",
      "2016-10-29  64728  64728  1.0000  0.5503\n",
      "2016-11-01  86304  86304  1.0000  0.4130\n",
      "2016-11-03  64728  64728  1.0000  0.3943\n",
      "2016-11-04  64728  64728  1.0000  0.4701\n",
      "2016-11-07 107880 107880  1.0000  0.4609\n",
      "2016-11-09  64728  59643  0.9214  0.3436\n",
      "2016-11-10 107880 107880  1.0000  0.4966\n",
      "2016-11-13 107880 107880  1.0000  0.4399\n",
      "2016-11-15  86304  86304  1.0000  0.4004\n"
     ]
    }
   ],
   "source": [
    "ind=1\n",
    "print(PolyResults[ind]['name'])\n",
    "print('date'.ljust(11), 'total', ' valid', '  ratio','average')\n",
    "print('---------- ------ ------  ------ -------')\n",
    "cutoff=0.9\n",
    "count=0\n",
    "maxcount=25\n",
    "for r in PolyResults[ind]['series']:\n",
    "    if r['result']['validCount']/r['result']['totalCount'] > cutoff and count<maxcount:\n",
    "        print(r['date'], '{0:6d}'.format(r['result']['totalCount']), '{0:6d}'.format(r['result']['validCount']), \n",
    "              ' {0:.4f}'.format(r['result']['validCount']/r['result']['totalCount']), ' {0:.4f}'.format(r['result']['average']))\n",
    "        count=count+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is strange: \n",
    "- the total number is the number of pixels in the polygon; it is <b>not</b> constant, probably because there are multiple entries per date in the time series.\n",
    "- the valid number is <b>not</b> constant and equal to total. As RADAR is cloud penetrating, there's no reason for pixels to be invalid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
